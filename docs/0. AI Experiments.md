# My personal AI Experiments
## 

A few months ago, I wanted to learn a bit more about the basics of AI and Neural networks.
I was so disappointed in the code quality of most of the 
AI / Neural network articles and tutorials I found, that I decided to develop my own, clean, object-oriented neural network [implementation](https://github.com/darlingVandamme/OONeuralNetwork).
This [first article](https://medium.com/@geertvandamme/building-an-object-oriented-neural-network-ee3f4af085b6) focuses on programming a neural network itself and is therefore quite technical.

But while coding my own neural network from scratch, I learned so much more. 
Even though I already knew quite a bit about AI, creating the basic building blocks myself gave me a whole new perspective.  
The following articles will explore a bit more the philosophical implications of what I found out doing these experiments.  
I just want to reflect on what I found out, what surprised me, what looked nice, what seemed interesting or stupid, where I see opportunities for new experiments etc... 
Some of these issues are already mentioned in the first article. At that time I didn't think I'd be writing a whole series on this.

## AI Disclaimer.

I'm not an AI expert who follows all the latest trends and technologies.
I just wanted to experiment a bit with AI at the lowest level
(i.e., programming it myself), and I learned a lot from it.
My background in psychology, cognitive science, philosophy and
software development in general gives these experiments a specific personal perspective and allows me to see things from different sides. 
The issues I'm talking about come from my own experience and thoughts.
They may sometimes be highly speculative and probably controversial, so feel free to disagree with some of my statements. ;-)

Some topics I want to discuss here are probably not unique and are surely being investigated by other companies and researchers at the moment.


I deliberately didn't explore this too much to keep my view fresh and original.
I did however, see this [interview with Max Tegmark](https://www.youtube.com/watch?v=_-Xdkzi8H_o) where he mentioned several ideas that I cover here as well, so that confirms me that my ideas are not totally useless.   

## Brain analogy
Some AI scientists focus on the computer algorithms and consider the neuron/brain pictures merely as an illustration or metaphor.
However, I think the brain analogy goes deeper and might serve as a guide to show us interesting future development opportunities. The way nature implemented intelligence, by the use of neurons and combining them in the form of brains, is a proven technology. 
This doesn't mean that it's the only viable solution to create intelligent systems, but it can be an example from which we can learn how to make our AI.

* Focus is still on computers. There are interesting experiments with hybrid digital/biological solutions. But that's not what I'm planning here.
* AI is more than Neural networks and more than LLMs
* todo: inspirational
* I'll be doing some more creative experiments in next months

todo: image Zappa Quote

## Ethical Objections

Many of the philosophical views on AI focus on the ethical issues and consequences of AI, and how AI is developing.
Misinformation, privacy, job displacement, security, AI singularity and energy use pose serious concerns on how we want AI to be further developed.
Although I have my ideas on these issues, both in a positive and negative direction, I won't be focusing on that here.

## Overview

After seeing the diversity in the topics I wanted to discuss, I decided to split it up in a series of articles.

### My experiments

### [Building an Object Oriented Neural Network](https://medium.com/@geertvandamme/building-an-object-oriented-neural-network-ee3f4af085b6)

Dissatisfied with the code quality and approach in most of the articles and tutorials on neural networks, I decided to write it myself, from scratch, clean. Like I think it should be coded. 

### Intelligent behavior

During my development, I used a very small, dummy network as a test example to check if my code worked fine.
I was surprised that even at this small size, the network showed some interesting properties, which made me think about (artificial) intelligence and consciousness.

### Driven vs. Limited by Technology

Technological innovations and frameworks help us to develop AI solutions, but they also limit our possibilities, without us realizing.
Our choices in hardware and software might limit our creativity in developing new AI solutions. 

### Training vs Learning

Training (in AI systems) is fundamentally different from learning (in ao. humans ) on several aspects. 
True intelligent systems will need to learn instead of just being trained.

### Serialization

A typical neural network is very easy to serialize (save, copy, duplicate,...)
Classical intelligence is very hard, or maybe impossible, to serialize.
Serializability has an impact on what a system can do and how it will behave. 

### Performance

How well does our self-developed network perform?
Is it possible to achieve good enough performance without matrix algorithms and GPU's?
What can we do to speed up the software?

---

Not all the different parts in this series are published at the same time. 
You might want to follow me if you want to stay updated. 

