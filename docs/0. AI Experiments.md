# My personal AI Experiments
## 

A few months ago, I was so disappointed in the code quality of many
AI / Neural network articles and tutorials, that I decided to develop
my own, clean, object-oriented neural network [implementation](https://github.com/darlingVandamme/OONeuralNetwork).
The [first article](https://medium.com/@geertvandamme/building-an-object-oriented-neural-network-ee3f4af085b6) focuses on the code itself and is therefore very technical.
But there's much more that I learned by coding my own neural network from scratch.  
The following articles will explore a bit more the philosophical implications of what I found out doing these experiments.  
I just want to reflect on what I found out, what surprised me, what looked nice, what seemed interesting or stupid etc... 
Some of these issues are already mentioned in the first article. At that time I didn't think I'd be writing a whole series on this.

## AI Disclaimer.

I'm not an AI expert who follows all the latest trends and technologies.
I just wanted to experiment a bit with AI at the lowest level
(i.e., programming it myself), and I learned a lot from it.
My background in psychology, cognitive science, philosophy and
software development in general gives these experiments a specific personal perspective and allows me to see things from different sides. 
The issues I'm talking about come from my own experience and thoughts.
They may sometimes be highly speculative and probably controversial, so feel free to disagree with my statements. ;-)

Some topics I want to discuss here are probably not new and are surely being investigated by other companies and researchers at the moment.
I deliberately didn't explore this too much to keep my view fresh and original.
I did however, see this [interview with Max Tegmark](https://www.youtube.com/watch?v=_-Xdkzi8H_o) where he mentioned several ideas that I cover here as well, so that confirms me that my ideas are not totally useless.   

* AI is more than Neural networks
* todo: inspirational
* I'll be doing some more creative experiments in next months
* Brain analogy
Some AI developers focus on the computer algorithms and consider the neuron/brain pictures merely as an illustration or metaphor. 
However, I think the brain analogy goes deeper and might serve as a guide to show us interesting future development opportunities. 

## Ethical Objections

Many of the philosophical views on AI focus on the ethical issues and consequences of AI, and how AI is developing.
Misinformation, privacy, job displacement, security, AI singularity and energy use pose serious concerns on how we want AI to be further developed.
Although I have my ideas on these issues, both in a positive and negative direction, I won't be focusing on that here.


## Overview

After seeing the diversity in the topics I wanted to discuss, I decided to split it up in a series of articles.

### My experiments

### [Building an Object Oriented Neural Network](https://medium.com/@geertvandamme/building-an-object-oriented-neural-network-ee3f4af085b6)

Dissatisfied with the code quality and approach in most of the articles and tutorials on neural networks, I decided to write it myself, from scratch, clean. Like I think it should be coded. 

### Intelligent behavior

During my development, I used a very small, dummy network as a test example to check if my code worked fine.
I was surprised that even at this small size, the network showed some interesting properties, which made me think about (artificial) intelligence and consciousness.

### Driven vs. Limited by Technology

Technological innovations and frameworks help us to develop AI solutions, but they also limit our possibilities, without us realizing.
Our choices in hardware and software might limit our creativity in developing new AI solutions. 

### Training vs Learning

Training (in AI systems) is fundamentally different from learning (in ao. humans ) on several aspects. 
True intelligent systems will need to learn instead of just being trained.

### Serialization

A typical neural network is very easy to serialize (save, copy, duplicate,...)
Classical intelligence is very hard, or maybe impossible, to serialize.
Serializability has an impact on what a system can do and how it will behave. 

### Performance

How well does our self-developed network perform?
Is it possible to achieve good enough performance without matrix algorithms and GPU's?
What can we do to speed up the software?

---

Not all the different parts in this series are published at the same time. 
You might want to follow me if you want to stay updated. 

